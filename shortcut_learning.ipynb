{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976757f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am loading the required packages, to run the code\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47781798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I specify the path to the best weights from our main model, YOLOv11\n",
    "model_path = r\"C:\\Users\\rasmn\\Desktop\\Speciale\\YOLO\\runs_YOLO11\\train\\weights\\best.pt\"\n",
    "\n",
    "# I specify the path to the first test image, since the model performed well on the unaltered version\n",
    "image_path = \"test_image1.jpg\"\n",
    "\n",
    "# I specify the output path, but I need to manually change it depending on which of the three configurations I choose further down.\n",
    "output_path = \"whiteout_mirrored_output.jpg\"\n",
    "#output_path = \"green_mirrored_output.jpg\"\n",
    "#output_path = \"flipped_green_mirrored_output.jpg\"\n",
    "\n",
    "# Specify which model to use, in this case our fine-tuned YOLOv11 model.\n",
    "model = YOLO(model_path)\n",
    "# Load the original image\n",
    "original_img = cv2.imread(image_path)\n",
    "\n",
    "# Load the height and width of the image\n",
    "h, w = original_img.shape[:2]\n",
    "\n",
    "# Use the fine-tuned model to detect the symbols on the page at a resolution of 2000 (while maintaining the aspect ratio as descriped in the thesis)\n",
    "results = model.predict(source=image_path, imgsz=2000)\n",
    "\n",
    "# Unpacks the bounding boxes from the results, moves the data from GPU to CPU and converts it to a numpy array\n",
    "boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "\n",
    "# Create an empty black mask of the same dimensions as the image\n",
    "mask = np.zeros((h, w), dtype=np.uint8)\n",
    "\n",
    "# For each bounding box, set the corresponding region in the mask to white so that we can later extract the symbols\n",
    "for box in boxes:\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    mask[y1:y2, x1:x2] = 255\n",
    "\n",
    "### FOR THE WHITE BACKGROUND REPLACE bg_color AND colored_bg WITH THIS LINE. CHANGE OUTPUT PATH AND BACKGROUND AS WELL ###\n",
    "\n",
    "#white_bg = 255 * np.ones_like(original_img)\n",
    "\n",
    "### FOR THE GREEN BACKGROUND REPLACE white_bg WITH THESE TWO LINES. CHANGE OUTPUT PATH AND BACKGROUND AS WELL ###\n",
    "\n",
    "# Define the RGB color for the background, here I used an online tool to tell me the RBG value of the background in the original image\n",
    "bg_color = [99, 123, 113]\n",
    "\n",
    "# We can then use this to create a full background image filled with the chosen color\n",
    "colored_bg = np.full_like(original_img, bg_color)\n",
    "\n",
    "# Extract only the parts of the original image that fall inside the mask (symbols)\n",
    "foreground = cv2.bitwise_and(original_img, original_img, mask=mask)\n",
    "\n",
    "# We can then combine the chosen background color with the inverted mask to fill the non-symbol areas, either with white or green\n",
    "background = cv2.bitwise_and(colored_bg, colored_bg, mask=255 - mask)\n",
    "#background = cv2.bitwise_and(white_bg, white_bg, mask= 255- mask)\n",
    "\n",
    "# We can then combine the foreground (which should be our labels) with the new background in a new image\n",
    "new_img = cv2.add(foreground, background)\n",
    "\n",
    "# The cv2.flip function is used to mirror the image to differentiate it further \n",
    "mirrored_img = cv2.flip(new_img, 1)\n",
    "\n",
    "# Optional addition of a vertical flip to further test generalization\n",
    "flipped_img = cv2.flip(mirrored_img, 0)\n",
    "\n",
    "# Finally we save the new image, based on the settings we chose, with to the specified name/folder\n",
    "#cv2.imwrite(output_path, mirrored_img)\n",
    "cv2.imwrite(output_path, flipped_img)\n",
    "print(f\"Saved the new image to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e84023",
   "metadata": {},
   "source": [
    "# The following sections do exactly the same thing, but they are simply set up to run each of the image variations. As such only one of these will be commented, but the comments are relevant for all three. Any code repeated from the previous section will also not be commented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cc1539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the packages and code required to run the following code brackets without having to run the above code again\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "\n",
    "model = YOLO(\"runs_YOLO11/train/weights/best.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_new = model.predict(source=\"whiteout_mirrored_output.jpg\", imgsz=2000)\n",
    "\n",
    "# Shows the image with all the bounding boxes our model was able to detect, along with their associated confidence score/label.\n",
    "results_new[0].show()\n",
    "\n",
    "# Create an empty dictionary of where every key has an empty list as default value, since we want to sum all confidence scores across each class.\n",
    "class_confidences = defaultdict(list)\n",
    "\n",
    "# Loop through each of the bounding boxes in the results variable \n",
    "for box in results_new[0].boxes:\n",
    "\n",
    "    # Save the class id associated with the bbox (as an integer, since it is 0 or 1)\n",
    "    cls_id = int(box.cls[0])\n",
    "    # Save the confidence associated with the bbox (as a float, since it is given as e.g. 0.81)\n",
    "    conf = float(box.conf[0])\n",
    "    # For every bounding box, append the associated confidence score. We end up with two keys, and each has an associated list of all the confidence scores for that class in the image.\n",
    "    class_confidences[cls_id].append(conf)\n",
    "\n",
    "# In the dictionary loop through each key (class) one at a time:\n",
    "for cls_id, confs in class_confidences.items():\n",
    "    # Access the list in the current key and sum its values, which is divided by the total number of confidence scores in the list providing an average score.\n",
    "    avg_conf = sum(confs) / len(confs)\n",
    "    # Print the average confidence score for each class/key rounding to 3 decimals \n",
    "    print(f\"Class: {cls_id}, Average Confidence: {avg_conf:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d510f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_new = model.predict(source=\"green_mirrored_output.jpg\", imgsz=2000)\n",
    "results_new[0].show()\n",
    "\n",
    "class_confidences = defaultdict(list)\n",
    "\n",
    "for box in results_new[0].boxes:\n",
    "    cls_id = int(box.cls[0])\n",
    "    conf = float(box.conf[0])\n",
    "    class_confidences[cls_id].append(conf)\n",
    "\n",
    "for cls_id, confs in class_confidences.items():\n",
    "    avg_conf = sum(confs) / len(confs)\n",
    "    print(f\"Class: {cls_id}, Average Confidence: {avg_conf:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4699d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_new = model.predict(source=\"flipped_green_mirrored_output.jpg\", imgsz=2000)\n",
    "results_new[0].show()\n",
    "\n",
    "class_confidences = defaultdict(list)\n",
    "\n",
    "for box in results_new[0].boxes:\n",
    "    cls_id = int(box.cls[0])\n",
    "    conf = float(box.conf[0])\n",
    "    class_confidences[cls_id].append(conf)\n",
    "\n",
    "for cls_id, confs in class_confidences.items():\n",
    "    avg_conf = sum(confs) / len(confs)\n",
    "    print(f\"Class: {cls_id}, Average Confidence: {avg_conf:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
