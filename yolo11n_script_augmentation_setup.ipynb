{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ded4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the code required to run the code below\n",
    "import os\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3864b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Was crashing due to an unknown error, and I found this workaround online. Apparently it solves some library conflicts when running multiple instances of Intels OpenMP.\n",
    "# I would recommend not running this section, as the code should ideally function without it\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d6ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to my datasets dataset.yaml file \n",
    "data_yaml_path = \"tiled_dataset/dataset.yaml\"\n",
    "\n",
    "# Specify the optimizer from the paper used as inspiration\n",
    "chosen_optimizer = \"AdamW\"\n",
    "\n",
    "# Specify how many epochs the model should run for\n",
    "epochs = 100\n",
    "# Specify which image size the model should rescale the input to\n",
    "imgsz = 640\n",
    "\n",
    "# Load the model\n",
    "v11_model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Here I override the current optimizer with the optimizer from the paper, which i specified before\n",
    "v11_model.overrides['optimizer'] = chosen_optimizer\n",
    "\n",
    "results = v11_model.train(\n",
    "    # Uses the dataset.yaml file to access the train/images and train/labels folders, as well as the validation folders\n",
    "    data=data_yaml_path,\n",
    "    epochs=epochs,\n",
    "    imgsz=imgsz,\n",
    "    # Run the training on my GPU\n",
    "    device=0,\n",
    "    # Specify that the computer should use less CPU to load the data, since I was running into crashes\n",
    "    workers=1,\n",
    "    # The batch size determines how many images the model has to go through before it updates its weights\n",
    "    batch=16,\n",
    "    learning_rate=0.01,\n",
    "\n",
    "    # Name of the folder in which the results and weights are saved\n",
    "    project=\"runs_YOLO11\",\n",
    "\n",
    "    # Here I apply the augmentations from paper, which is discussed in more detail in the thesis\n",
    "    degrees=10,           \n",
    "    shear=15,\n",
    "    hsv_v=0.25,\n",
    "\n",
    "    # Since the papers used to inspire the augmentation did not mention these augmentations, I am disabling them\n",
    "    mosaic=0.0,\n",
    "    mixup=0.0,\n",
    "    flipud=0.0,\n",
    "    fliplr=0.0,\n",
    "    translate=0.0,\n",
    "    scale=0.0,\n",
    "    perspective=0.0,\n",
    "    hsv_h=0.0,\n",
    "    hsv_s=0.0,\n",
    "    copy_paste=0.0,\n",
    "    erasing=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3262da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the package in each code section, so I run the following code brackets seperately\n",
    "from ultralytics import YOLO\n",
    "# Loading the best.pt weights from the YOLOv11 model above\n",
    "v11_model = YOLO(\"runs_YOLO11/train/weights/best.pt\")\n",
    "\n",
    "# Run validation on our test split and saving it in runs_YOLO11 in a folder called \"val\". The model uses the path in the dataset.yaml file to find the \"test\" split \n",
    "validation_results = v11_model.val(\n",
    "    data=\"tiled_dataset/dataset.yaml\",\n",
    "    split=\"test\",\n",
    "    project=\"runs_YOLO11\",\n",
    "    name=\"val\",\n",
    "    exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca80f702",
   "metadata": {},
   "source": [
    "# The following section is to test how the model performs on the unlabeled images. The code is a bit crude, but I set it up like this so I could check any of the images without running the rest of the code. After each instance I have to compute the average confidence before running inference on the next image, since the results variable is overwritten every time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee7084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the package in each code section, so I run the following code brackets seperately\n",
    "from ultralytics import YOLO\n",
    "# Loading the best.pt weights from the YOLOv11 model above\n",
    "v11_model = YOLO(\"runs_YOLO11/train/weights/best.pt\")\n",
    "# Use the this fine-tuned model to run inference on our first unlabeled image\n",
    "results = v11_model.predict(source=\"test_image1.jpg\", imgsz=2000)\n",
    "# Make the image pop up, with its class predictions and confidence scores\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb14eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "v11_model = YOLO(\"runs_YOLO11/train/weights/best.pt\")\n",
    "results = v11_model.predict(source=\"test_image2.jpg\", imgsz=2000)\n",
    "\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b911fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "v11_model = YOLO(\"runs_YOLO11/train/weights/best.pt\")\n",
    "results = v11_model.predict(source=\"test_image3.jpg\", imgsz=2000)\n",
    "\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc50da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "v11_model = YOLO(\"runs_YOLO11/train/weights/best.pt\")\n",
    "results = v11_model.predict(source=\"test_image4.jpg\", imgsz=2000)\n",
    "\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "v11_model = YOLO(\"runs_YOLO11/train/weights/best.pt\")\n",
    "results = v11_model.predict(source=\"test_image5.jpg\", imgsz=2000)\n",
    "\n",
    "results[0].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1a1448",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "# Create an empty dictionary of where every key has an empty list as default value, since we want to sum all confidence scores across each class\n",
    "class_confidences = defaultdict(list)\n",
    "\n",
    "# Loop through each of the bounding boxes in the results variable \n",
    "for box in results_new[0].boxes:\n",
    "\n",
    "    # Save the class id associated with the bbox (as an integer, since it is 0 or 1)\n",
    "    cls_id = int(box.cls[0])\n",
    "    # Save the confidence associated with the bbox (as a float, since it is given as e.g. 0.81)\n",
    "    conf = float(box.conf[0])\n",
    "    # For every bounding box, append the associated confidence score. We end up with two keys, and each has an associated list of all the confidence scores for that class in the image\n",
    "    class_confidences[cls_id].append(conf)\n",
    "\n",
    "# In the dictionary loop through each key (class) one at a time:\n",
    "for cls_id, confs in class_confidences.items():\n",
    "    # Access the list in the current key and sum its values, which is divided by the total number of confidence scores in the list providing an average score\n",
    "    avg_conf = sum(confs) / len(confs)\n",
    "    # Print the average confidence score for each class/key rounding to 3 decimals \n",
    "    print(f\"Class: {cls_id}, Average Confidence: {avg_conf:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
