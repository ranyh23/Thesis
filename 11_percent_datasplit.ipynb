{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I load the packages need to run the code\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0cb3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the full dataset, while also providing a path to the labels and images in the train, test and val folders.\n",
    "source_dir = Path(\"tiled_dataset\")\n",
    "train_img_dir = source_dir / \"images\" / \"train\"\n",
    "train_lbl_dir = source_dir / \"labels\" / \"train\"\n",
    "\n",
    "val_img_dir = source_dir / \"images\" / \"val\"\n",
    "val_lbl_dir = source_dir / \"labels\" / \"val\"\n",
    "test_img_dir = source_dir / \"images\" / \"test\"\n",
    "test_lbl_dir = source_dir / \"labels\" / \"test\"\n",
    "\n",
    "# Decide which size we want the create the subsets in. In our case we used 11% since this brought the size of the training data down to around the same amount of images\n",
    "# we had before cropping. Note that this is a list, so that we could create multiple subsets at once if we wished. \n",
    "subsets = [0.11]\n",
    "\n",
    "\n",
    "# Specify the class names associated to each label value \n",
    "class_names = {\n",
    "    0: \"Carrot\",\n",
    "    1: \"Cross\"\n",
    "}\n",
    "\n",
    "# Get list of all training images (here you would obviously need to change the .jpg depending on your fileformat, we're using .jpg though)\n",
    "all_train_images = list(train_img_dir.glob(\"*.jpg\"))\n",
    "\n",
    "# Here we loop through all the desired subsets (in our case only the 11% subset)\n",
    "for pct in subsets:\n",
    "    # We convert the float value to an integer for the purpose of naming the folder in which we save our \"new\" dataset\n",
    "    pct_int = int(pct * 100)\n",
    "    # We save the new subset a folder named \"tiled_data11\"\n",
    "    subset_dir = Path(f\"tiled_data{pct_int}\")\n",
    "\n",
    "    # Create folder structure which matches the one from the original dataset, since YOLO expects this folder structure\n",
    "    (subset_dir / \"images\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "    (subset_dir / \"labels\" / \"train\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    (subset_dir / \"images\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "    (subset_dir / \"labels\" / \"val\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    (subset_dir / \"images\" / \"test\").mkdir(parents=True, exist_ok=True)\n",
    "    (subset_dir / \"labels\" / \"test\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Specify the number of samples (images) which should be selected\n",
    "    num_samples = int(len(all_train_images) * pct)\n",
    "\n",
    "    # Based on this value, select a random sample from the training images. The random.sample function returns a list\n",
    "    selected_images = random.sample(all_train_images, num_samples)\n",
    "\n",
    "    # Now we can loop through each of the selected images \n",
    "    for img in selected_images:\n",
    "        # Copy each of the images into the new images/train folder \n",
    "        shutil.copy(img, subset_dir / \"images\" / \"train\" / img.name)\n",
    "\n",
    "        # Now we can extract the corresponding label from the original labels/train folder by using the img.stem function to replace \".jpg\" with \".txt\"\n",
    "        # which is the name of the corresponding label file\n",
    "        label = train_lbl_dir / f\"{img.stem}.txt\"\n",
    "        # if that label exists, copy it to the new tiled_data11/labels/train\n",
    "        if label.exists():\n",
    "            shutil.copy(label, subset_dir / \"labels\" / \"train\" / label.name)\n",
    "\n",
    "    # Since making a subset of the validation and test set is irrelevant, we just copy full validation and test sets\n",
    "    for file in val_img_dir.glob(\"*\"):\n",
    "        shutil.copy(file, subset_dir / \"images\" / \"val\" / file.name)\n",
    "    for file in val_lbl_dir.glob(\"*\"):\n",
    "        shutil.copy(file, subset_dir / \"labels\" / \"val\" / file.name)\n",
    "    \n",
    "    \n",
    "    for file in test_img_dir.glob(\"*\"):\n",
    "        shutil.copy(file, subset_dir / \"images\" / \"test\" / file.name)\n",
    "    for file in test_lbl_dir.glob(\"*\"):\n",
    "        shutil.copy(file, subset_dir / \"labels\" / \"test\" / file.name)\n",
    "\n",
    "    # Create dataset.yaml with required format, which points to the correct folders and dataset folder. \n",
    "    yaml_path = subset_dir / \"dataset.yaml\"\n",
    "    with open(yaml_path, \"w\") as f:\n",
    "        f.write(f\"path: {subset_dir.resolve()}\\n\")\n",
    "        f.write(\"train: images/train\\n\")\n",
    "        f.write(\"val: images/val\\n\")\n",
    "        f.write(\"test: images/test\\n\")\n",
    "        f.write(\"names:\\n\")\n",
    "\n",
    "        # loops through the dictionary of class names and adds them to the .yaml file.\n",
    "        for idx, name in class_names.items():\n",
    "            f.write(f\"  {idx}: {name}\\n\")\n",
    "\n",
    "# Prints when the code is done\n",
    "print(\"Dataset created\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
